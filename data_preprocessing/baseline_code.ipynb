{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NATX0bAZNln8"
      },
      "source": [
        "### Library Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z3Or4rTINln9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import List, Dict\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import lightgbm as lgb\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMsth-PvNln-"
      },
      "source": [
        "### Data Load"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12xVaQH8O77A",
        "outputId": "94beea61-2ce9-471c-bc4f-b1b01741194b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9XS4DPONNln_"
      },
      "outputs": [],
      "source": [
        "# 파일 호출\n",
        "data_path: str = \"/content/drive/MyDrive/data\"\n",
        "train_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"train.csv\")).assign(_type=\"train\") # train 에는 _type = train\n",
        "test_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")).assign(_type=\"test\") # test 에는 _type = test\n",
        "submission_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")) # ID, target 열만 가진 데이터 미리 호출\n",
        "df: pd.DataFrame = pd.concat([train_df, test_df], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUEVGWFfNln_",
        "outputId": "4b2d398a-4bc3-4b4d-f770-abb4bd66d56a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 107/107 [00:06<00:00, 15.89it/s]\n"
          ]
        }
      ],
      "source": [
        "# HOURLY_ 로 시작하는 .csv 파일 이름을 file_names 에 할딩\n",
        "file_names: List[str] = [\n",
        "    f for f in os.listdir(data_path) if f.startswith(\"HOURLY_\") and f.endswith(\".csv\")\n",
        "]\n",
        "\n",
        "# 파일명 : 데이터프레임으로 딕셔너리 형태로 저장\n",
        "file_dict: Dict[str, pd.DataFrame] = {\n",
        "    f.replace(\".csv\", \"\"): pd.read_csv(os.path.join(data_path, f)) for f in file_names\n",
        "}\n",
        "\n",
        "for _file_name, _df in tqdm(file_dict.items()):\n",
        "    # 열 이름 중복 방지를 위해 {_file_name.lower()}_{col.lower()}로 변경, datetime 열을 ID로 변경\n",
        "    _rename_rule = {\n",
        "        col: f\"{_file_name.lower()}_{col.lower()}\" if col != \"datetime\" else \"ID\"\n",
        "        for col in _df.columns\n",
        "    }\n",
        "    _df = _df.rename(_rename_rule, axis=1)\n",
        "    df = df.merge(_df, on=\"ID\", how=\"left\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 거래소별 EDA"
      ],
      "metadata": {
        "id": "S1kDMn3FPRco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "거래소 간 지표들의 차이들이 유효한지 확인하기 위한 기본적인 EDA를 진행합니다. 여기서는 거래소가 여러개이기 때문에 renaming을 진행하지 않고 raw name으로 진행하겠습니다."
      ],
      "metadata": {
        "id": "ufrwiKqJPhEL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbDL_UnINloA"
      },
      "source": [
        "### Rename 이후 EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYYfhExmNloE",
        "outputId": "eabd8d42-5539-462c-c7a3-ecc42dff2b39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11552, 19)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델에 사용할 컬럼, 컬럼의 rename rule을 미리 할당함\n",
        "cols_dict: Dict[str, str] = {\n",
        "    \"ID\": \"ID\",\n",
        "    \"target\": \"target\",\n",
        "    \"_type\": \"_type\",\n",
        "    \"hourly_market-data_coinbase-premium-index_coinbase_premium_gap\": \"coinbase_premium_gap\",\n",
        "    \"hourly_market-data_funding-rates_all_exchange_funding_rates\": \"funding_rates\",\n",
        "    \"hourly_market-data_liquidations_all_exchange_all_symbol_long_liquidations\": \"long_liquidations\",\n",
        "    \"hourly_market-data_liquidations_all_exchange_all_symbol_short_liquidations\": \"short_liquidations\",\n",
        "    \"hourly_market-data_open-interest_all_exchange_all_symbol_open_interest\": \"open_interest\",\n",
        "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_ratio\": \"buy_ratio\",\n",
        "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_sell_ratio\": \"buy_sell_ratio\",\n",
        "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_volume\": \"buy_volume\",\n",
        "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_sell_ratio\": \"sell_ratio\",\n",
        "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_sell_volume\": \"sell_volume\",\n",
        "    \"hourly_network-data_addresses-count_addresses_count_active\": \"active_count\",\n",
        "    \"hourly_network-data_addresses-count_addresses_count_receiver\": \"receiver_count\",\n",
        "    \"hourly_network-data_addresses-count_addresses_count_sender\": \"sender_count\",\n",
        "    'hourly_network-data_block-interval_block_interval':'block_interval',\n",
        "    'hourly_network-data_block-count_block_count':'block_count',\n",
        "    'hourly_network-data_block-bytes_block_bytes':'block_bytes',\n",
        "    'hourly_network-data_blockreward_blockreward':'blockreward',\n",
        "    'hourly_network-data_transactions-count_transactions_count_total': 'transaction_count',\n",
        "    'hourly_network-data_tokens-transferred_tokens_transferred_total': 'token_transferred',\n",
        "    'hourly_network-data_tokens-transferred_tokens_transferred_mean':\n",
        "    'token_transferred_mean',\n",
        "    'hourly_network-data_tokens-transferred_tokens_transferred_median':\n",
        "    'token_transferred_median',\n",
        "    'hourly_network-data_hashrate_hashrate':\n",
        "    'hashrate',\n",
        "    'hourly_network-data_difficulty_difficulty':\n",
        "    'difficulty',\n",
        "    'houtransaction_fees_transaction_meanrly_network-data_fees-':\n",
        "    'fees_transaction',\n",
        "    'hourly_network-data_fees_fees_total':\n",
        "    'fees',\n",
        "    'hourly_network-data_velocity_velocity_supply_total':\n",
        "    'velocity_supply',\n",
        "    'hourly_network-data_utxo-count_utxo_count':\n",
        "    'utxo_count',\n",
        "    'hourly_network-data_supply_supply_total':\n",
        "    'supply_total',\n",
        "    'hourly_network-data_supply_supply_new':\n",
        "    'supply_new',\n",
        "    'hourly_network-data_fees_fees_block_mean':\n",
        "    'fees_block_mean',\n",
        "    'hourly_network-data_fees-transaction_fees_transaction_median':\n",
        "    'fees_transaction_median',\n",
        "\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "df = df[cols_dict.keys()].rename(cols_dict, axis=1)\n",
        "df.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVaxKISNNloE"
      },
      "source": [
        "### Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2t1_QCpNloF"
      },
      "outputs": [],
      "source": [
        "# eda 에서 파악한 차이와 차이의 음수, 양수 여부를 새로운 피쳐로 생성\n",
        "df = df.assign(\n",
        "    liquidation_diff=df[\"long_liquidations\"] - df[\"short_liquidations\"],\n",
        "    liquidation_usd_diff=df[\"long_liquidations_usd\"] - df[\"short_liquidations_usd\"],\n",
        "    volume_diff=df[\"buy_volume\"] - df[\"sell_volume\"],\n",
        "    liquidation_diffg=np.sign(df[\"long_liquidations\"] - df[\"short_liquidations\"]),\n",
        "    liquidation_usd_diffg=np.sign(df[\"long_liquidations_usd\"] - df[\"short_liquidations_usd\"]),\n",
        "    volume_diffg=np.sign(df[\"buy_volume\"] - df[\"sell_volume\"]),\n",
        "    buy_sell_volume_ratio=df[\"buy_volume\"] / (df[\"sell_volume\"] + 1),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bem1yblNloF"
      },
      "outputs": [],
      "source": [
        "def shift_feature(\n",
        "    df: pd.DataFrame,\n",
        "    conti_cols: List[str],\n",
        "    intervals: List[int],\n",
        ") -> List[pd.Series]:\n",
        "    \"\"\"\n",
        "    연속형 변수의 shift feature 생성\n",
        "    Args:\n",
        "        df (pd.DataFrame)\n",
        "        conti_cols (List[str]): continuous colnames\n",
        "        intervals (List[int]): shifted intervals\n",
        "    Return:\n",
        "        List[pd.Series]\n",
        "    \"\"\"\n",
        "    df_shift_dict = [\n",
        "        df[conti_col].shift(interval).rename(f\"{conti_col}_{interval}\")\n",
        "        for conti_col in conti_cols\n",
        "        for interval in intervals\n",
        "    ]\n",
        "    return df_shift_dict\n",
        "\n",
        "# 최대 24시간의 shift 피쳐를 계산\n",
        "shift_list = shift_feature(\n",
        "    df=df, conti_cols=conti_cols, intervals=[_ for _ in range(1, 24)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EY2lRH1NloG"
      },
      "outputs": [],
      "source": [
        "# concat 하여 df 에 할당\n",
        "df = pd.concat([df, pd.concat(shift_list, axis=1)], axis=1)\n",
        "\n",
        "# 타겟 변수를 제외한 변수를 forwardfill, -999로 결측치 대체\n",
        "_target = df[\"target\"]\n",
        "df = df.ffill().fillna(-999).assign(target = _target)\n",
        "\n",
        "# _type에 따라 train, test 분리\n",
        "train_df = df.loc[df[\"_type\"]==\"train\"].drop(columns=[\"_type\"])\n",
        "test_df = df.loc[df[\"_type\"]==\"test\"].drop(columns=[\"_type\"])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
