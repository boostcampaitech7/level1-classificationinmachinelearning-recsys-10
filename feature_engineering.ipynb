{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcocmEkWeJfD"
   },
   "source": [
    "### 소개\n",
    "\n",
    "이 파일은 이전까지 진행된 EDA를 기반으로 column name들을 rename 하고 새로운 파생변수를 생성해서 모델에서 학습할 수 있도록 train_df.csv, test_df.csv 파일로 save 되는 과정이 담겨져 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NATX0bAZNln8"
   },
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Z3Or4rTINln9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMsth-PvNln-"
   },
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9XS4DPONNln_"
   },
   "outputs": [],
   "source": [
    "# 파일 호출\n",
    "data_path: str = \"data/raw\"\n",
    "train_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"train.csv\")).assign(_type=\"train\") # train 에는 _type = train\n",
    "test_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")).assign(_type=\"test\") # test 에는 _type = test\n",
    "submission_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")) # ID, target 열만 가진 데이터 미리 호출\n",
    "df: pd.DataFrame = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUEVGWFfNln_",
    "outputId": "5947ad11-7f95-4467-e69b-c7f9f65ee03e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 107/107 [00:01<00:00, 76.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# HOURLY_ 로 시작하는 .csv 파일 이름을 file_names 에 할딩\n",
    "file_names: List[str] = [\n",
    "    f for f in os.listdir(data_path) if f.startswith(\"HOURLY_\") and f.endswith(\".csv\")\n",
    "]\n",
    "\n",
    "# 파일명 : 데이터프레임으로 딕셔너리 형태로 저장\n",
    "file_dict: Dict[str, pd.DataFrame] = {\n",
    "    f.replace(\".csv\", \"\"): pd.read_csv(os.path.join(data_path, f)) for f in file_names\n",
    "}\n",
    "\n",
    "for _file_name, _df in tqdm(file_dict.items()):\n",
    "    # 열 이름 중복 방지를 위해 {_file_name.lower()}_{col.lower()}로 변경, datetime 열을 ID로 변경\n",
    "    _rename_rule = {\n",
    "        col: f\"{_file_name.lower()}_{col.lower()}\" if col != \"datetime\" else \"ID\"\n",
    "        for col in _df.columns\n",
    "    }\n",
    "    _df = _df.rename(_rename_rule, axis=1)\n",
    "    df = df.merge(_df, on=\"ID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVaxKISNNloE"
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASvMHCz3E_rW"
   },
   "source": [
    "가격 지표는 test_df에는 포함 되어 있지 않지만 가격을 회귀로 예측하여 예측한 값을 입력피쳐로 활용하여 target을 예측하여 볼 수 있고 파생지표 또한 활용할 수 있는 방안이 있어 df에 포함시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gN97ehgh9lM9"
   },
   "outputs": [],
   "source": [
    "close_price = df['hourly_market-data_price-ohlcv_all_exchange_spot_btc_usd_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYYfhExmNloE",
    "outputId": "b9ef4908-625e-4cd0-bef9-cd58abbff53f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11552, 34)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델에 사용할 컬럼, 컬럼의 rename rule을 미리 할당함\n",
    "cols_dict: Dict[str, str] = {\n",
    "    \"ID\": \"ID\",\n",
    "    \"target\": \"target\",\n",
    "    \"_type\": \"_type\",\n",
    "    \"hourly_market-data_coinbase-premium-index_coinbase_premium_gap\": \"coinbase_premium_gap\",\n",
    "    \"hourly_market-data_funding-rates_all_exchange_funding_rates\": \"funding_rates\",\n",
    "    \"hourly_market-data_liquidations_all_exchange_all_symbol_long_liquidations\": \"long_liquidations\",\n",
    "    \"hourly_market-data_liquidations_all_exchange_all_symbol_short_liquidations\": \"short_liquidations\",\n",
    "    \"hourly_market-data_open-interest_all_exchange_all_symbol_open_interest\": \"open_interest\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_ratio\": \"buy_ratio\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_sell_ratio\": \"buy_sell_ratio\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_buy_volume\": \"buy_volume\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_sell_ratio\": \"sell_ratio\",\n",
    "    \"hourly_market-data_taker-buy-sell-stats_all_exchange_taker_sell_volume\": \"sell_volume\",\n",
    "    \"hourly_network-data_addresses-count_addresses_count_active\": \"active_count\",\n",
    "    \"hourly_network-data_addresses-count_addresses_count_receiver\": \"receiver_count\",\n",
    "    \"hourly_network-data_addresses-count_addresses_count_sender\": \"sender_count\",\n",
    "    'hourly_network-data_block-interval_block_interval':'block_interval',\n",
    "    'hourly_network-data_block-count_block_count':'block_count',\n",
    "    'hourly_network-data_block-bytes_block_bytes':'block_bytes',\n",
    "    'hourly_network-data_blockreward_blockreward':'blockreward',\n",
    "    'hourly_network-data_transactions-count_transactions_count_total': 'transaction_count',\n",
    "    'hourly_network-data_tokens-transferred_tokens_transferred_total': 'token_transferred',\n",
    "    'hourly_network-data_tokens-transferred_tokens_transferred_mean':\n",
    "    'token_transferred_mean',\n",
    "    'hourly_network-data_tokens-transferred_tokens_transferred_median':\n",
    "    'token_transferred_median',\n",
    "    'hourly_network-data_hashrate_hashrate':\n",
    "    'hashrate',\n",
    "    'hourly_network-data_difficulty_difficulty':\n",
    "    'difficulty',\n",
    "    'hourly_network-data_fees-transaction_fees_transaction_mean':\n",
    "    'fees_transaction',\n",
    "    'hourly_network-data_fees_fees_total':\n",
    "    'fees',\n",
    "    'hourly_network-data_velocity_velocity_supply_total':\n",
    "    'velocity_supply',\n",
    "    'hourly_network-data_utxo-count_utxo_count':\n",
    "    'utxo_count',\n",
    "    'hourly_network-data_supply_supply_total':\n",
    "    'supply_total',\n",
    "    'hourly_network-data_supply_supply_new':\n",
    "    'supply_new',\n",
    "    'hourly_network-data_fees_fees_block_mean':\n",
    "    'fees_block_mean',\n",
    "    'hourly_network-data_fees-transaction_fees_transaction_median':\n",
    "    'fees_transaction_median',\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "df = df[cols_dict.keys()].rename(cols_dict, axis=1)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Sfk_FCy9Glnv"
   },
   "outputs": [],
   "source": [
    "# 새로 만든 컬럼들을 담을 리스트 conti_cols\n",
    "conti_cols = []\n",
    "\n",
    "# cols_dict에서 ID, target, _type과 같은 변수들을 제외하고 conti_cols에 추가\n",
    "exclude_keys = ['ID', 'target', '_type']\n",
    "\n",
    "# 조건에 맞게 연속형 변수로 간주할 수 있는 컬럼들만 추가\n",
    "for key, value in cols_dict.items():\n",
    "    if key not in exclude_keys:\n",
    "        conti_cols.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "22u_crIIEmDW"
   },
   "outputs": [],
   "source": [
    "df['close_price'] = close_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "w2t1_QCpNloF"
   },
   "outputs": [],
   "source": [
    "# eda 에서 파악한 차이와 차이의 음수, 양수 여부를 새로운 피쳐로 생성\n",
    "df = df.assign(\n",
    "    liquidation_diff=df[\"long_liquidations\"] - df[\"short_liquidations\"],\n",
    "    volume_diff=df[\"buy_volume\"] - df[\"sell_volume\"],\n",
    "    liquidation_diffg=np.sign(df[\"long_liquidations\"] - df[\"short_liquidations\"]),\n",
    "    volume_diffg=np.sign(df[\"buy_volume\"] - df[\"sell_volume\"]),\n",
    "    buy_sell_volume_ratio=df[\"buy_volume\"] / (df[\"sell_volume\"] + 1),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9APQPIR8B74E"
   },
   "outputs": [],
   "source": [
    "# 새로 추가한 칼럼들 conti_cols에 추가\n",
    "new_cols = [\"liquidation_diff\", \"volume_diff\", \"buy_sell_volume_ratio\"]\n",
    "\n",
    "# 이미 만들어진 conti_cols에 추가\n",
    "conti_cols.extend(new_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8nx2BWa8cUv"
   },
   "source": [
    "#### Market 파생변수\n",
    "\n",
    "마켓 관련된 파생변수를 추가합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "USA79anX9Fze"
   },
   "outputs": [],
   "source": [
    "# 0 나오는거 방지\n",
    "eps = 1e-8\n",
    "df['coinbase_premium_gap'] = df['coinbase_premium_gap'] + eps\n",
    "\n",
    "\n",
    "# 1. volatility 지수 | 변동성 지표\n",
    "df['premium_gap_volatility'] = df['coinbase_premium_gap'].rolling(window=6).std()\n",
    "\n",
    "# 2. liquidation(long and short) 대비 open interest 비율\n",
    "df['long_liquidation_to_open_interest_ratio'] = df['long_liquidations'] / df['open_interest']\n",
    "df['short_liquidation_to_open_interest_ratio'] = df['short_liquidations'] / df['open_interest']\n",
    "\n",
    "# 3. Funding rate MACD\n",
    "df['funding_rate_ema_short'] = df['funding_rates'].ewm(span=12).mean()\n",
    "df['funding_rate_ema_long'] = df['funding_rates'].ewm(span=24).mean()\n",
    "df['funding_rate_macd'] = df['funding_rate_ema_short'] - df['funding_rate_ema_long']\n",
    "\n",
    "# 4. open interest 불린져 밴드 계산\n",
    "oi_ma6 = df['open_interest'].rolling(window=6).mean()  # 6기간 이동 평균\n",
    "oi_std6 = df['open_interest'].rolling(window=6).std()   # 6기간 이동 표준 편차\n",
    "\n",
    "df['oi_upper_band'] = oi_ma6 + oi_std6 * 2\n",
    "df['oi_lower_band'] = oi_ma6 - oi_std6 * 2\n",
    "\n",
    "# 5. funding_rates 사용하여 RSI 계산\n",
    "delta = df['funding_rates'].diff()\n",
    "up = delta.clip(lower=0)\n",
    "down = -1 * delta.clip(upper=0)\n",
    "roll_up = up.rolling(window=6).mean()\n",
    "roll_down = down.rolling(window=6).mean()\n",
    "rs = roll_up / (roll_down + 1e-9)\n",
    "df['funding_rates_rsi'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# 6. 이동 지수 표준 편차\n",
    "df['oi_ewm_volatility'] = df['open_interest'].ewm(span=3, adjust=False).std()\n",
    "\n",
    "# 7. 시장 총 거래량\n",
    "df['total_volume'] = df['buy_volume'] + df['sell_volume']\n",
    "\n",
    "# 8. buying selling volume 차이 MA\n",
    "df['taker_volume_oscillator'] = df['buy_volume'].rolling(window=5).mean() - df['sell_volume'].rolling(window=5).mean()\n",
    "\n",
    "# 9. Market sentiment index\n",
    "df['market_sentiment'] = (df['buy_ratio'] - df['sell_ratio']) * df['open_interest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CJAOZvVKNluO"
   },
   "outputs": [],
   "source": [
    "# 새로 생성된 컬럼들 리스트\n",
    "new_market_cols = [\n",
    "    'premium_gap_volatility',\n",
    "    'long_liquidation_to_open_interest_ratio',\n",
    "    'short_liquidation_to_open_interest_ratio',\n",
    "    'funding_rate_ema_short',\n",
    "    'funding_rate_ema_long',\n",
    "    'funding_rate_macd',\n",
    "    'oi_upper_band',\n",
    "    'oi_lower_band',\n",
    "    'funding_rates_rsi',\n",
    "    'oi_ewm_volatility',\n",
    "    'total_volume',\n",
    "    'taker_volume_oscillator',\n",
    "    'market_sentiment'\n",
    "]\n",
    "\n",
    "# conti_cols에 새로운 피처 추가\n",
    "conti_cols.extend(new_market_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFNdUTHIA7ZU"
   },
   "source": [
    "#### Network 파생변수\n",
    "\n",
    "네트워크 관련된 파생변수를 추가합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSLLPs4_AsH1",
    "outputId": "0840db34-12d0-4fc6-eeb2-3c1e81306d9f"
   },
   "outputs": [],
   "source": [
    "# 0 방지\n",
    "df['supply_new'] = df['supply_new']+eps\n",
    "\n",
    "# 1. UTXO growth rate\n",
    "df['utxo_growth_rate'] = df['utxo_count'].pct_change() * 100\n",
    "\n",
    "# 2. Average UTXO per Transaction\n",
    "df['avg_utxo_per_transaction'] = df['utxo_count'] / df['transaction_count']\n",
    "\n",
    "# 3. Velocity Change Rate\n",
    "df['velocity_change_rate'] = df['velocity_supply'].pct_change() * 100\n",
    "\n",
    "# 4. Velocity to UTXO Ratio\n",
    "df['velocity_to_utxo_ratio'] = df['velocity_supply'] / df['utxo_count']\n",
    "\n",
    "# 5. Velocity to Supply Ratio\n",
    "df['velocity_to_supply_ratio'] = df['velocity_supply'] / df['supply_total']\n",
    "\n",
    "# 6. Active address growth\n",
    "df['active_address_growth_rate'] = df['active_count'].pct_change() * 100\n",
    "\n",
    "# 7. Sender-Receiver Ratio\n",
    "df['sender_receiver_ratio'] = df['sender_count'] / df['receiver_count']\n",
    "\n",
    "# 8. Address Distribution Index\n",
    "df['address_distribution_index'] = (df['sender_count'] + df['receiver_count']) / df['active_count']\n",
    "\n",
    "# 9. Block Interval Change Rate\n",
    "df['block_interval_change_rate'] = df['block_interval'].pct_change() * 100\n",
    "\n",
    "# 10. Block Utilization\n",
    "df['block_utilization'] = df['block_bytes'] / df['block_count']\n",
    "\n",
    "# 11. Block Reward to Difficulty Ratio\n",
    "df['block_reward_to_difficulty_ratio'] = df['blockreward'] / df['difficulty']\n",
    "\n",
    "# 12. Fee to Transaction Ratio\n",
    "df['fee_to_transaction_ratio'] = df['fees_transaction'] / df['transaction_count']\n",
    "\n",
    "# 13. Fees Growth Rate\n",
    "df['fees_growth_rate'] = df['fees'].pct_change() * 100\n",
    "\n",
    "# 14. Mining Cost Efficiency\n",
    "df['mining_cost_efficiency'] = df['fees_block_mean'] / df['difficulty']\n",
    "\n",
    "# 15. Transaction per Supply Ratio\n",
    "df['transaction_per_supply_ratio'] = df['transaction_count'] / df['supply_total']\n",
    "\n",
    "# 16. Velocity to Supply Ratio\n",
    "df['velocity_to_supply_ratio'] = df['velocity_supply'] / df['supply_total']\n",
    "\n",
    "# 17. Supply Change Rate\n",
    "df['supply_change_rate'] = (df['supply_total'].diff() / df['supply_total'].shift(1)) * 100\n",
    "\n",
    "# 18. UTXO Growth Rate\n",
    "df['utxo_growth_rate'] = df['utxo_count'].pct_change() * 100\n",
    "\n",
    "# 19. Token Transfer Efficiency\n",
    "df['token_transfer_efficiency'] = df['token_transferred'] / df['transaction_count']\n",
    "\n",
    "# 20. Velocity to UTXO Ratio\n",
    "df['velocity_to_utxo_ratio'] = df['velocity_supply'] / df['utxo_count']\n",
    "\n",
    "# 21. network activity\n",
    "df['network_activity_index'] = df['active_count'] * (df['receiver_count'] + df['sender_count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LpvvZpzgPZTK"
   },
   "outputs": [],
   "source": [
    "# 새로 추가된 컬럼들 리스트\n",
    "new_network_cols = [\n",
    "    'utxo_growth_rate',\n",
    "    'avg_utxo_per_transaction',\n",
    "    'velocity_change_rate',\n",
    "    'velocity_to_utxo_ratio',\n",
    "    'velocity_to_supply_ratio',\n",
    "    'active_address_growth_rate',\n",
    "    'sender_receiver_ratio',\n",
    "    'address_distribution_index',\n",
    "    'block_interval_change_rate',\n",
    "    'block_utilization',\n",
    "    'block_reward_to_difficulty_ratio',\n",
    "    'fee_to_transaction_ratio',\n",
    "    'fees_growth_rate',\n",
    "    'mining_cost_efficiency',\n",
    "    'transaction_per_supply_ratio',\n",
    "    'supply_change_rate',\n",
    "    'token_transfer_efficiency',\n",
    "    'network_activity_index'\n",
    "]\n",
    "\n",
    "# conti_cols에 새로운 피처 추가\n",
    "conti_cols.extend(new_network_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcHQtyEqCl3c"
   },
   "source": [
    "#### 가격 관련 파생변수\n",
    "\n",
    "test_df 에는 가격 데이타가 없습니다. 하지만, 가격 예측을 어느 정도 맞게 할 수 있다면 비트코인 시장의 시그널을 잘 보여주는 파생변수를 가격을 이용해 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lH8sCeij5dR2"
   },
   "source": [
    "가격\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IAav3gp6DJ-Q"
   },
   "outputs": [],
   "source": [
    "# stock to flow ratio 계산 이후 SF reversion 계산\n",
    "df['stock_to_flow_ratio'] = df['supply_total']/df['supply_new']\n",
    "df['SF_reversion'] = df['close_price']/df['stock_to_flow_ratio']\n",
    "df['SF_reversion']\n",
    "\n",
    "# market cap 계산\n",
    "df['market_cap'] = df['close_price'] * df['supply_total']\n",
    "\n",
    "# NVT ratio\n",
    "df['NVT_Ratio'] = df['market_cap']/df['transaction_count']\n",
    "\n",
    "# NVT ratio의 평균과 표준편차를 이용해 불린저 밴드 계산\n",
    "window = 72 # 임의적으로 72 시간 설정\n",
    "\n",
    "NVT_ma = df['NVT_Ratio'].rolling(window=window).mean()\n",
    "NVT_std = df['NVT_Ratio'].rolling(window=window).std()\n",
    "\n",
    "# 상단 밴드 및 하단 밴드 설정 (Bollinger Bands)\n",
    "df['NVT_Upper_Band'] = NVT_ma + 2 * NVT_std\n",
    "df['NVT_Lower_Band'] = NVT_ma - 2 * NVT_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c0hqecSUJNC",
    "outputId": "7ee1258f-880b-4cbb-efd3-168682b0c1b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로 만든 피처들 리스트\n",
    "new_price_cols = [\n",
    "    'stock_to_flow_ratio',\n",
    "    'SF_reversion',\n",
    "    'market_cap',\n",
    "    'NVT_Ratio',\n",
    "    'NVT_Upper_Band',\n",
    "    'NVT_Lower_Band'\n",
    "]\n",
    "\n",
    "# conti_cols에 새로운 피처 추가\n",
    "conti_cols.extend(new_price_cols)\n",
    "\n",
    "# 중복 방지\n",
    "conti_cols = list(set(conti_cols))\n",
    "len(conti_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snd3mCWDUxyK"
   },
   "source": [
    "#### Diff, MA, Shift 피쳐 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DI06OnL_U4Gj"
   },
   "source": [
    "기본적으로 시장의 흐름에 따라 가격의 변동이 달라질 수 있으므로 흐름을 반영할 수 있는 지표들이 중요합니다. 이를 위해 지금까지 continuous 한 column 들로 모아놓은 conti_cols에서 difference, difference의 difference (지표가 변하는 속력과 가속도), shift, ma를 계산해서 지표로 넣을 필요가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tmcmOKnpWgmd"
   },
   "outputs": [],
   "source": [
    "def diff_feature(\n",
    "    df: pd.DataFrame,\n",
    "    conti_cols: List[str],\n",
    ") -> Tuple[List[pd.Series], List[pd.Series]]:\n",
    "    \"\"\"\n",
    "    연속형 변수의 diff와 diff의 diff를 계산하여 리스트로 반환\n",
    "    Args:\n",
    "        df (pd.DataFrame): 데이터프레임\n",
    "        conti_cols (List[str]): 연속형 변수 컬럼 리스트\n",
    "    Return:\n",
    "        (List[pd.Series], List[pd.Series]): diff_list, diff_diff_list\n",
    "    \"\"\"\n",
    "    # diff 계산\n",
    "    diff_list = [\n",
    "        df[conti_col].diff().rename(f\"{conti_col}_diff\")\n",
    "        for conti_col in conti_cols\n",
    "    ]\n",
    "\n",
    "    # diff의 diff 계산\n",
    "    diff_diff_list = [\n",
    "        df[conti_col].diff().diff().rename(f\"{conti_col}_diff_diff\")\n",
    "        for conti_col in conti_cols\n",
    "    ]\n",
    "\n",
    "    return diff_list, diff_diff_list\n",
    "\n",
    "# diff와 diff의 diff 계산\n",
    "diff_list, diff_diff_list = diff_feature(df=df, conti_cols=conti_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0bem1yblNloF"
   },
   "outputs": [],
   "source": [
    "def shift_feature(\n",
    "    df: pd.DataFrame,\n",
    "    conti_cols: List[str],\n",
    "    intervals: List[int],\n",
    ") -> List[pd.Series]:\n",
    "    \"\"\"\n",
    "    연속형 변수의 shift feature 생성\n",
    "    Args:\n",
    "        df (pd.DataFrame)\n",
    "        conti_cols (List[str]): continuous colnames\n",
    "        intervals (List[int]): shifted intervals\n",
    "    Return:\n",
    "        List[pd.Series]\n",
    "    \"\"\"\n",
    "    df_shift_dict = [\n",
    "        df[conti_col].shift(interval).rename(f\"{conti_col}_{interval}\")\n",
    "        for conti_col in conti_cols\n",
    "        for interval in intervals\n",
    "    ]\n",
    "    return df_shift_dict\n",
    "\n",
    "# 최대 12시간의 shift 피쳐를 계산\n",
    "shift_list = shift_feature(\n",
    "    df=df, conti_cols=conti_cols, intervals=[_ for _ in range(1, 12)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "w3j81p0eXJPM"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "def ma_feature(\n",
    "    df: pd.DataFrame,\n",
    "    conti_cols: List[str],\n",
    "    window_sizes: List[int]\n",
    ") -> List[pd.Series]:\n",
    "    \"\"\"\n",
    "    연속형 변수의 이동평균(MA)을 여러 윈도우 크기로 계산하여 리스트로 반환\n",
    "    Args:\n",
    "        df (pd.DataFrame): 데이터프레임\n",
    "        conti_cols (List[str]): 연속형 변수 컬럼 리스트\n",
    "        window_sizes (List[int]): MA를 계산할 여러 윈도우 크기 리스트\n",
    "    Return:\n",
    "        List[pd.Series]: ma_list\n",
    "    \"\"\"\n",
    "    # 여러 윈도우 크기에 대해 이동평균(MA) 계산\n",
    "    ma_list = [\n",
    "        df[conti_col].rolling(window=window_size).mean().rename(f\"{conti_col}_ma_{window_size}\")\n",
    "        for conti_col in conti_cols\n",
    "        for window_size in window_sizes\n",
    "    ]\n",
    "\n",
    "    return ma_list\n",
    "\n",
    "# 여러 윈도우 크기로 이동평균(MA) 계산 3, 6, 12 시간 적용\n",
    "ma_list = ma_feature(df=df, conti_cols=conti_cols, window_sizes=[3, 6, 12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6EY2lRH1NloG"
   },
   "outputs": [],
   "source": [
    "# 새로 생성된 리스트들을 데이터프레임으로 변환\n",
    "diff_df = pd.concat(diff_list, axis=1)\n",
    "diff_diff_df = pd.concat(diff_diff_list, axis=1)\n",
    "shift_df = pd.concat(shift_list, axis=1)\n",
    "ma_df = pd.concat(ma_list, axis=1)\n",
    "\n",
    "# 원본 df에 새로운 피처들을 concat\n",
    "df = pd.concat([df, diff_df, diff_diff_df, shift_df, ma_df], axis=1)\n",
    "\n",
    "\n",
    "# 타겟 변수를 제외한 변수를 forwardfill, -999로 결측치 대체\n",
    "_target = df[\"target\"]\n",
    "df = df.ffill().fillna(-999).assign(target = _target)\n",
    "\n",
    "# _type에 따라 train, test 분리\n",
    "train_df = df.loc[df[\"_type\"]==\"train\"].drop(columns=[\"_type\"])\n",
    "test_df = df.loc[df[\"_type\"]==\"test\"].drop(columns=[\"_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtkVZn9oY7-W",
    "outputId": "b4ab61f6-fd4b-45e4-dcc8-51c7e48a4c11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.csv 파일이 data/preprocessed에 저장되었습니다.\n",
      "test_df.csv 파일이 data/preprocessed에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# data/preprocessed에 저장 없다면 생성\n",
    "preprocessed_data_path = \"data/preprocessed\"\n",
    "os.makedirs(preprocessed_data_path, exist_ok=True)\n",
    "\n",
    "train_df.to_csv(os.path.join(preprocessed_data_path, \"train_df.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(preprocessed_data_path, \"test_df.csv\"), index=False)\n",
    "\n",
    "# 저장 확인\n",
    "print(f\"train_df.csv 파일이 {preprocessed_data_path}에 저장되었습니다.\")\n",
    "print(f\"test_df.csv 파일이 {preprocessed_data_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
